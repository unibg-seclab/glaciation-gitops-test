apiVersion: v1
kind: ConfigMap
metadata:
  name: data-sanitization-config
  namespace: spark-app
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: HookSucceeded
data:
  adults.json: |-
    {
        "columnScoringFunction": "entropy",
        "driver": {
            "memory": "1g"
        },
        "executor": {
            "instances": 4,
            "memory": "1g"
        },
        "idAttributes": [
            "capital-loss",
            "capital-gain"
        ],
        "informationLossMeasures": [
            "discernabilityPenalty",
            "globalCertaintyPenalty"
        ],
        "input": "s3a://sanitization/dataset/adults.csv",
        "isFullyDistributed": false,
        "k": 3,
        "l": 2,
        "output": "s3a://sanitization/anonymized/adults.csv",
        "partitionFunction": "quantile",
        "quasiIdAttributes": [
            "age",
            "education-num",
            "race",
            "native-country"
        ],
        "redact": true,
        "sensitiveAttributes": [
            "income" 
        ]
    }
---
apiVersion: batch/v1
kind: Job
metadata:
  name: data-sanitization-smoke-test
  namespace: spark-app
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: HookSucceeded
spec:
  template:
    spec:
      containers:
      - name: curl
        image: curlimages/curl:8.7.1
        envFrom:
        - secretRef:
            name: minio-credentials
        command:
        - /bin/sh
        - -c
        - |
          set -e # make sure the job fails if any instruction fails

          echo -e '[*] Install MinIO client and jq';
          curl https://dl.min.io/client/mc/release/linux-amd64/mc \
            --create-dirs \
            --output /tmp/bin/mc;
          curl https://github.com/jqlang/jq/releases/download/jq-1.7/jq-linux-amd64 \
            --create-dirs \
            --location \
            --output /tmp/bin/jq;
          chmod +x /tmp/bin/mc /tmp/bin/jq;
          export PATH=$PATH:/tmp/bin/;
          echo -e '\n[*] Setup object store for the sanitization process';
          mc alias set minio https://minio.minio-tenant.svc.cluster.local $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY;
          mc mb minio/sanitization/dataset;
          mc mb minio/sanitization/anonymized;
          curl --output /tmp/adults.csv https://raw.githubusercontent.com/mosaicrown/mondrian/k8s/distributed/dataset/adults.csv
          mc cp /tmp/adults.csv minio/sanitization/dataset/;
          echo -e '\n\n[*] Peak into the contents of the dataset'
          mc head minio/sanitization/dataset/adults.csv;
          echo -e '\n[*] Run sanitization job'
          REQ_ID=$(
              curl \
                  --silent \
                  --request POST \
                  --header 'Content-Type: application/json' \
                  --data @/tmp/adults.json \
                  http://data-sanitization.spark-app.svc.cluster.local/api/v1alpha1/job | jq -r .id
          );
          echo -e '\nWaiting for the completion of the sanitization job...';
          STATUS="UNKNOWN";
          while [ "$STATUS" != "COMPLETED" ]; do
              sleep 5;
              STATUS=$(
                  curl \
                      --silent \
                      --request GET \
                      --header 'Content-Type: application/json' \
                      http://data-sanitization.spark-app.svc.cluster.local/api/v1alpha1/job/$REQ_ID/status | jq -r .state
              );
              echo "Data sanitization job with id=$REQ_ID has status=$STATUS";
          done;
          echo -e '\n[*] Showcase a sample of the output';
          mc ls minio/sanitization/anonymized;
          mc ls minio/sanitization/anonymized/adults.csv;
          PART=$(mc ls --json minio/sanitization/anonymized/adults.csv | jq -r '.key | select(startswith("part-00000-")) | select(endswith(".csv"))');
          mc head minio/sanitization/anonymized/adults.csv/$PART;
          echo -e '\n[*] Delete sanitization job';
          curl \
            --silent \
            --request DELETE \
            --header 'Content-Type: application/json' \
            --output /dev/null \
            http://data-sanitization.spark-app.svc.cluster.local/api/v1alpha1/job/$REQ_ID
        securityContext:
          privileged: false
          runAsUser: 100
          runAsGroup: 101
          allowPrivilegeEscalation: false
          capabilities:
            drop:
              - ALL
        volumeMounts:
        - mountPath: /etc/ssl/certs/ca.crt
          subPath: ca.crt
          name: ca-bundle
          readOnly: true
        - mountPath: /tmp/adults.json
          subPath: adults.json
          name: data-sanitization-config
          readOnly: true
      restartPolicy: Never
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      volumes:
      - name: ca-bundle
        configMap:
          defaultMode: 422
          name: ca-bundle
      - name: data-sanitization-config
        configMap:
          defaultMode: 422
          name: data-sanitization-config
  backoffLimit: 5
